{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDUEDNUJp_l0"
      },
      "source": [
        "\"\"\"\n",
        "LOAD CODE AND PRETRAINED MODELS, VOCAB FILE\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHvvKUDcrqoK",
        "outputId": "c3c875a1-0d99-448d-ce23-9c0fd0f77c58"
      },
      "source": [
        "%cd code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "oxirv6m-rlj7",
        "outputId": "651ef08e-1c58-4be1-f38c-d66e8c4488fb"
      },
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!python setupNltk.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (7.1.2)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 2)) (1.15.0)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHECxoBc04iD",
        "outputId": "48286537-4475-43f3-c23b-26979c9d6b21"
      },
      "source": [
        "!git clone https://github.com/windx0303/VIST-Challenge-NAACL-2018 ../VIST-Challenge-NAACL-2018\n",
        "# http://visionandlanguage.net/workshop2018/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '../VIST-Challenge-NAACL-2018'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Total 193 (delta 0), reused 0 (delta 0), pack-reused 193\u001b[K\n",
            "Receiving objects: 100% (193/193), 110.31 MiB | 32.04 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "157tzFs4qnbF",
        "outputId": "e3cd110a-c462-4fa0-b720-2a66647425c2"
      },
      "source": [
        "\"\"\" One can see the results from early epochs by changing the model_num below, and by providing the file \"\"\"\n",
        "!python eval.py --model_num 41 --log_step 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda is enabled...\n",
            "Step [0/41], Loss: 3.0839, Perplexity: 21.8425\n",
            "Step [5/41], Loss: 3.0117, Perplexity: 20.3223\n",
            "Step [10/41], Loss: 2.9300, Perplexity: 18.7278\n",
            "Step [15/41], Loss: 3.1875, Perplexity: 24.2278\n",
            "Step [20/41], Loss: 3.2331, Perplexity: 25.3593\n",
            "Step [25/41], Loss: 2.9640, Perplexity: 19.3746\n",
            "Step [30/41], Loss: 3.0509, Perplexity: 21.1340\n",
            "Step [35/41], Loss: 3.1837, Perplexity: 24.1350\n",
            "Step [40/41], Loss: 1.6453, Perplexity: 5.1824\n",
            "Average Loss: 3.0431, Average Perplexity: 20.9703\n",
            "Total story size : 774\n",
            "[Passed] Test file is in valid JSON syntax.\n",
            "[Passed] Each photo sequence has only one story.\n",
            "[Passed] All required stories are submitted.\n",
            "MeteorConfiguration...\n",
            "setTask...\n",
            "scorer created...\n",
            "--------------------------\n",
            "Avg. Max Meteor Score =\n",
            "0.3001369681984237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHTLgi0a71I5",
        "outputId": "953d1b26-c074-47e0-94bb-a8013e1e0d5f"
      },
      "source": [
        "!python eval.py --model_num 19 --log_step 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda is enabled...\n",
            "Step [0/41], Loss: 3.0425, Perplexity: 20.9570\n",
            "Step [5/41], Loss: 2.9429, Perplexity: 18.9700\n",
            "Step [10/41], Loss: 2.9607, Perplexity: 19.3121\n",
            "Step [15/41], Loss: 3.1101, Perplexity: 22.4231\n",
            "Step [20/41], Loss: 3.1029, Perplexity: 22.2616\n",
            "Step [25/41], Loss: 2.9257, Perplexity: 18.6478\n",
            "Step [30/41], Loss: 2.9764, Perplexity: 19.6180\n",
            "Step [35/41], Loss: 3.0490, Perplexity: 21.0946\n",
            "Step [40/41], Loss: 1.6065, Perplexity: 4.9854\n",
            "Average Loss: 2.9620, Average Perplexity: 19.3368\n",
            "Total story size : 774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REFERENCES\n",
        "\n",
        "1- Huang, T.H., Ferraro, F., Mostafazadeh, N., Misra, I., Devlin, J., Agrawal, A., Girshick, R., He, X., Kohli, P., Batra, D., & others (2016).\n",
        "Visual Storytelling. In 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2016).\n",
        "\n",
        "2-Kim, T., Heo, M.O., Son, S., Park, K.W., & Zhang, B.T.. (2018). GLAC Net: GLocal Attention Cascading Networks for Multi-image Cued Story Generation. \n",
        "https://github.com/tkim-snu/GLACNet\n",
        "\n",
        "3-http://visionandlanguage.net/workshop2018/"
      ],
      "metadata": {
        "id": "kxhn3C2fUuL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}